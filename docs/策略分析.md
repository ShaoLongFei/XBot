# 智能客服 Hackathon 项目策略分析

## 问题

从产品经理和项目管理的角度，帮我分析解决此问题，暂时只需给出回复，无需创建 PR

## 回复

### 一、核心目标分析

**评分机制解读**：
- 答案优于人工客服：6-9分（优质回答）
- 答案正确但不如人工：5分（及格线）
- 答案错误或不相关：1-4分（失败）

**关键洞察**：平均分最高获胜，这意味着**稳定性比个别亮点更重要**。策略应该是"保5争8"，避免大量低分回答。

---

### 二、3天时间分配建议

#### Day 1（第一天）：数据分析 + 方案选型（40%）
- **上午（4h）**：快速数据探索
- **下午（4h）**：技术方案确定 + 环境搭建

#### Day 2（第二天）：核心功能开发（45%）
- **全天（8h）**：模型调优 + 核心功能实现

#### Day 3（第三天）：优化 + 测试（15%）
- **上午（3h）**：测试评估 + 问题修复
- **下午（2h）**：最终调优 + 提交准备

---

### 三、关键步骤文档

#### 第一步：快速数据分析（Day 1 上午，4小时）

**目标**：了解数据特征，识别问题类型分布

**具体任务**：
1. **数据概览**（1h）
   - 统计问题总数、平均长度、问答对完整性
   - 识别缺失值、异常数据
   
2. **问题分类**（2h）
   - 使用简单规则或关键词对问题进行分类（如：账户问题、支付问题、功能咨询等）
   - 统计各类问题占比（找出高频问题类型）
   - 识别标准化问题（FAQ类，这些最容易拿高分）

3. **难度评估**（1h）
   - 区分简单问题（FAQ、流程类）vs 复杂问题（个性化咨询、技术细节）
   - **关键决策**：确定要覆盖的问题范围（覆盖80%简单问题 > 覆盖100%所有问题）

**交付物**：
- 数据分析报告（简单文档或表格）
- 问题类型分布图
- 高频问题列表（Top 50-100）

---

#### 第二步：技术方案选型（Day 1 下午，4小时）

**推荐策略：混合方案（稳定性优先）**

考虑到只有3天时间，建议采用**分层策略**：

**方案 A：快速实用型（推荐）**
```
第一层：FAQ匹配（处理30-40%标准问题）
  ↓ 匹配失败
第二层：语义检索（处理40-50%相似问题）
  ↓ 检索失败或低置信度
第三层：LLM生成（处理10-20%复杂问题）
  ↓ 兜底
第四层：默认回复（礼貌引导人工客服）
```

**方案 B：纯大模型方案（风险较高）**
- 优点：开发快，上限高
- 缺点：成本高，可能不稳定，容易产生幻觉导致低分

**技术选型建议**：
1. **FAQ匹配层**：
   - 工具：ElasticSearch / 简单的文本相似度（TF-IDF）
   - 数据：提取历史数据中的高频标准问答对（人工整理Top 100）

2. **语义检索层**：
   - 工具：向量数据库（Milvus/Pinecone）或简单的FAISS
   - 模型：使用预训练的中文Embedding模型（如：text2vec-chinese）
   - 数据：历史所有问答对向量化

3. **LLM生成层**：
   - API选择：优先考虑七牛云自家的LLM服务（可能有内部折扣）
   - 备选：通义千问、文心一言、ChatGLM（国内服务响应快）
   - Prompt设计：提供历史相似案例作为上下文（Few-shot）

4. **兜底策略**：
   - 低置信度时，返回通用回复："您的问题我们已收到，将由专业客服尽快为您解答"

**关键决策点**：
- ✅ 优先保证**召回率**（能匹配上问题）而非精确率
- ✅ 为每个回答设置**置信度阈值**（低于阈值使用兜底）
- ✅ 记录所有决策日志，便于Day 3快速定位问题

**交付物**：
- 技术方案文档（架构图）
- 环境搭建完成（开发环境、API密钥、数据库）
- 代码框架搭建（基础流程代码）

---

#### 第三步：数据准备与预处理（Day 1 晚上 + Day 2 上午，3小时）

**任务分工建议**（3人团队）：
- **成员A**：FAQ库整理（人工筛选100-200对高质量问答）
- **成员B**：向量化处理（将历史数据转为embeddings）
- **成员C**：数据清洗（去重、格式统一、质量过滤）

**关键质量控制**：
- 去除明显的错误回答（人工客服回复质量参差不齐）
- 统一格式（问题-答案对标准化）
- 补充缺失信息（如链接、联系方式使用最新的）

**交付物**：
- 清洗后的训练数据集
- FAQ知识库（JSON/CSV格式）
- 向量数据库导入完成

---

#### 第四步：核心功能开发（Day 2，8小时）

**开发优先级**：
1. **P0（必须完成）**：
   - FAQ匹配模块（2h）
   - 语义检索模块（3h）
   - 基础API接口（1h）
   
2. **P1（重要）**：
   - LLM调用模块（1.5h）
   - 置信度评分机制（0.5h）

3. **P2（可选）**：
   - 日志监控
   - 简单UI界面

**开发建议**：
- 使用成熟框架（FastAPI / Flask）快速搭建
- 每个模块独立测试，确保可替换性
- 实时测试：边开发边用测试集验证效果

**交付物**：
- 可运行的智能客服系统
- 基础测试通过（烟雾测试）

---

#### 第五步：测试与优化（Day 3 上午，3小时）

**测试策略**：
1. **抽样测试**（1h）
   - 从最近一个月数据中随机抽取100条
   - 人工对比回答质量
   - 统计各分数段占比

2. **问题诊断**（1h）
   - 找出得1-4分的case
   - 分类问题原因（匹配失败？回答错误？）
   
3. **快速修复**（1h）
   - 调整置信度阈值
   - 补充FAQ库
   - 优化Prompt（如果使用LLM）

**优化重点**：
- ⚠️ **不要过度优化**：时间有限，focus在"降低低分率"而非"提高高分率"
- 优先修复导致1-4分的系统性问题
- 调整策略：如果LLM不稳定，降低其使用比例

**交付物**：
- 测试报告（各分数段占比预估）
- 优化后的系统版本

---

#### 第六步：最终准备与提交（Day 3 下午，2小时）

1. **系统稳定性检查**（0.5h）
   - 压力测试（批量请求不崩溃）
   - 异常处理（API超时、服务降级）

2. **文档准备**（1h）
   - 系统说明文档
   - 技术方案介绍
   - 可能需要PPT演示

3. **最终提交**（0.5h）
   - 按组委会要求提交代码/系统
   - 准备现场演示

---

### 四、风险管理与应对

| 风险 | 概率 | 影响 | 应对措施 |
|------|------|------|----------|
| LLM API不稳定/超限 | 高 | 高 | 准备多个API备选，设置本地缓存 |
| 数据质量差 | 中 | 高 | Day 1必须完成数据评估，预留清洗时间 |
| 时间不够 | 高 | 中 | 严格按优先级开发，P2功能可砍 |
| 团队分工不明确 | 中 | 中 | Day 1明确分工，每日站会同步 |
| 测试集与训练集分布不同 | 中 | 高 | Day 2尽早拿到测试集样本验证 |

---

### 五、成功关键因素

1. **策略保守**：优先保证准确率（宁可说"不知道"也不乱答）
2. **快速迭代**：Day 2下午必须有可测试版本
3. **数据为王**：花足够时间理解数据特征
4. **团队协作**：明确分工，每日同步进度
5. **降级方案**：每层都要有兜底，避免系统性失败

---

### 六、额外建议

**如果七牛内部资源可用**：
- 内部LLM服务（可能有API额度支持）
- 历史客服数据的访问权限和数据字典
- 内部技术专家咨询（特别是了解评分标准的人）

**差异化优势**：
- 考虑针对七牛业务特点定制（如CDN、对象存储相关问题）
- 如果能获得产品文档，可以增强回答的专业性

**最后**：Hackathon的关键是在有限时间内交付可用的产品，完美是优秀的敌人。祝你们取得好成绩！🎯
